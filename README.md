# TilmashÂ Translator

**TilmashÂ Translator** is an offlineâ€‘first, privacyâ€‘preserving translation and readability toolkit for Russian, EnglishÂ andÂ Kazakh.

It ships as a Streamlit webâ€‘app and offers two core capabilities:

1. **Neural Machine Translation**  
   â€¢Â Primary modelÂ â€” [ISSAI/tilmash](https://huggingface.co/issai/tilmash) (Seq2Seq) for RUÂ â†”Â ENÂ â†”Â KK  
   â€¢Â Longâ€‘text fallbackÂ â€” *Gemmaâ€‘3* 12B (GGUF) running locally with `llamaâ€‘cpp-python`Â (+ optional GPU layers)  
   â€¢Â Smart chunking & streaming make multiâ€‘page documents feel snappy
2. **Readability Analysis**  
   â€¢Â Calculates FleschÂ ReadingÂ Ease, Fleschâ€‘Kincaid, GunningÂ Fog andÂ SMOG  
   â€¢Â Highlights complex words and supports RU/EN/KK


---

## QuickÂ Start

```bash
# 1. Clone & create a virtual environment
$ git clone https://github.com/medetshatayev/Tilmash_Translator.git
$ cd Tilmash_Translator
$ python3 -m venv .venv && source .venv/bin/activate

# 2. Install dependencies
$ pip install -r requirements.txt

# 3. (optional) authenticate once to download the Tilmash weights
$ echo "HF_TOKEN=ðŸª„your_huggingface_token" > .env

# 4. Launch the Streamlit app
$ streamlit run main.py
```

ðŸ’¡Â The helper script `start.sh` automates the above and sets safe memory limits for `llamaâ€‘cpp-python`.

### GPU Offâ€‘loading (Gemmaâ€‘3)

Set `GEMMA_GPU_LAYERS=<num_layers>` in your environment (defaults to **48**) to offâ€‘load those layers to Metal/CUDA.

---

## ProjectÂ Layout

```
.
â”œâ”€â”€ main.py               # Streamlit UI
â”œâ”€â”€ utils/                # Translation & analysis helpers
â”‚   â”œâ”€â”€ tilmash_translation.py
â”‚   â”œâ”€â”€ gemma_translation.py
â”‚   â”œâ”€â”€ readability_indices.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/               # Extra resources (NLTK, etc.)
â”œâ”€â”€ config.py             # Default envâ€‘vars
â”œâ”€â”€ start.sh              # Convenience launcher
â””â”€â”€ requirements.txt      # Python deps
```

## ConfigurationÂ Keys

| Variable               | Default | Purpose                                   |
|------------------------|---------|-------------------------------------------|
| `GEMMA_GPU_LAYERS`     | 48      | Layers to move to GPU (0Â = CPUâ€‘only)      |
| `GEMMA_CONTEXT_SIZE`   | 8192    | Context window for Gemmaâ€‘3                |
| `MAX_PARALLEL_MODELS`  | 4       | Concurrency guard                         |
| `MAX_TOKENS`           | 4096    | Generation cap per request                |
| `CHUNK_SIZE`           | 3000    | Token threshold before autoâ€‘chunking      |

Override any of these via the environment or edit **config.py**.

---

## HowÂ ItÂ Works

1. **File ingestion**Â â€” `.txt`, `.docx`, `.pdf` loaded via `utils/file_readers.py`  
2. **Language detection**Â â€” `langdetect` (autoâ€‘detect option in UI)  
3. **Translation pipeline**Â â€” <3000 tokens translate directly; longer texts are chunked (`utils/chunking.py`) and streamed through Tilmash or Gemmaâ€‘3  
4. **Readability analysis**Â â€” scores computed in `utils/readability_indices.py` and colorâ€‘coded in the app.

---

## License

Distributed under the MIT License â€” see `LICENSE` for details.

## Acknowledgements

- ISSAI team for releasing **Tilmash**  
- Meta for openâ€‘sourcing *Gemmaâ€‘3*  
- Streamlit, Hugging Face and the PythonÂ OSS community